{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "gpu melody.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YeweiYuan/melody/blob/master/gpu_melody.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ASzwnxsLr-6j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "from music21 import converter, instrument, note, chord, stream\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNfY2P5EscWM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#读取训练数据的Note\n",
        "filepath='../home/all/'\n",
        "files=os.listdir(filepath)\n",
        "Notes=[]\n",
        "for file in files:\n",
        "  try:\n",
        "        stream = converter.parse(filepath+file)\n",
        "        instru = instrument.partitionByInstrument(stream)\n",
        "        if instru:  # 如果有乐器部分，取第一个乐器部分\n",
        "            notes = instru.parts[0].recurse()\n",
        "        else:  #如果没有乐器部分，直接取note\n",
        "            notes = stream.flat.notes\n",
        "        for element in notes:\n",
        "              # 如果是 Note 类型，取音调\n",
        "              # 如果是 Chord 类型，取音调的序号,存int类型比较容易处理\n",
        "            if isinstance(element, note.Note):\n",
        "                Notes.append(str(element.pitch))\n",
        "            elif isinstance(element, chord.Chord):\n",
        "                Notes.append('.'.join(str(n) for n in element.normalOrder))\n",
        "  except:\n",
        "      pass\n",
        "  #记得注释掉\n",
        "  #with open('Note', 'a+')as f:\n",
        "      #f.write(str(Notes))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M9aQqV9n-kCU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "notes = Notes\n",
        "\n",
        "notes_len=len(set(notes))\n",
        "note_name=sorted(set(i for i in notes))#获得排序的不重复的音符名字\n",
        "sequence_length = 100 #序列长度\n",
        "note_dict=dict((j,i) for i,j in enumerate(note_name))#设计一个字典，把音符转换成数字，方便训练\n",
        "\n",
        "network_input = []#创建输入序列\n",
        "network_output = []#创建输出序列\n",
        "for i in range(0, len(notes) - sequence_length):\n",
        "    #输入100个，输出1个\n",
        "    sequence_in = notes[i: i + sequence_length]\n",
        "    sequence_out = notes[i + sequence_length]\n",
        "    network_input.append([note_dict[k] for k in sequence_in])\n",
        "    network_output.append(note_dict[sequence_out])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4XhRKTaz_BRX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "network_input = np.reshape(network_input, (len(network_input), sequence_length, 1))\n",
        "normal_network_input = network_input / float(notes_len) #归一化\n",
        "\n",
        "network_output = tf.keras.utils.to_categorical(network_output)#输出布尔矩阵，配合categorical_crossentropy 算法使用"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EiF0S50KAfzK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a = normal_network_input[0:2]\n",
        "b = network_output[0:2]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rmEZVbCry1fL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_model(inputs, notes_len, weights_file=None):\n",
        "    model = tf.keras.models.Sequential()\n",
        "    model.add(tf.keras.layers.LSTM(512,input_shape=(inputs.shape[1], inputs.shape[2]),return_sequences=True))#512层神经元，return_sequences=True表示返回所有的输出序列\n",
        "    model.add(tf.keras.layers.Dropout(0.3))  # 丢弃 30% 神经元，防止过拟合\n",
        "    model.add(tf.keras.layers.LSTM(512, return_sequences=True))\n",
        "    model.add(tf.keras.layers.Dropout(0.3))\n",
        "    model.add(tf.keras.layers.LSTM(512))  # return_sequences 是默认的 False，只返回输出序列的最后一个\n",
        "    model.add(tf.keras.layers.Dense(256))  # 256 个神经元的全连接层\n",
        "    model.add(tf.keras.layers.Dropout(0.3))\n",
        "    model.add(tf.keras.layers.Dense(notes_len))  # 输出的数目等于所有不重复的音调的数目\n",
        "    model.add(tf.keras.layers.Activation('softmax'))\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adadelta')\n",
        " \n",
        "    if weights_file is not None:\n",
        "        model.load_weights(weights_file)\n",
        " \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DpMQVUilTXUd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.set_printoptions(threshold=6)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "elMfQQNtTSBY",
        "colab_type": "code",
        "outputId": "fd52a20d-f06a-410a-a60f-73785ca2681c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "normal_network_input[1]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.978907  ],\n",
              "       [0.978907  ],\n",
              "       [0.978907  ],\n",
              "       [0.57718121],\n",
              "       [0.77660594],\n",
              "       [0.978907  ],\n",
              "       [0.95589645],\n",
              "       [0.978907  ],\n",
              "       [0.5033557 ],\n",
              "       [0.978907  ],\n",
              "       [0.978907  ],\n",
              "       [0.93959732],\n",
              "       [0.57718121],\n",
              "       [0.12655801],\n",
              "       [0.5033557 ],\n",
              "       [0.978907  ],\n",
              "       [0.978907  ],\n",
              "       [0.978907  ],\n",
              "       [0.57718121],\n",
              "       [0.93959732],\n",
              "       [0.978907  ],\n",
              "       [0.95589645],\n",
              "       [0.978907  ],\n",
              "       [0.978907  ],\n",
              "       [0.5033557 ],\n",
              "       [0.978907  ],\n",
              "       [0.978907  ],\n",
              "       [0.93959732],\n",
              "       [0.57718121],\n",
              "       [0.12655801],\n",
              "       [0.5033557 ],\n",
              "       [0.978907  ],\n",
              "       [0.978907  ],\n",
              "       [0.978907  ],\n",
              "       [0.57718121],\n",
              "       [0.58485139],\n",
              "       [0.93959732],\n",
              "       [0.978907  ],\n",
              "       [0.95589645],\n",
              "       [0.978907  ],\n",
              "       [0.978907  ],\n",
              "       [0.5033557 ],\n",
              "       [0.978907  ],\n",
              "       [0.978907  ],\n",
              "       [0.93959732],\n",
              "       [0.57718121],\n",
              "       [0.12655801],\n",
              "       [0.5033557 ],\n",
              "       [0.978907  ],\n",
              "       [0.978907  ],\n",
              "       [0.978907  ],\n",
              "       [0.57718121],\n",
              "       [0.93959732],\n",
              "       [0.978907  ],\n",
              "       [0.95589645],\n",
              "       [0.978907  ],\n",
              "       [0.978907  ],\n",
              "       [0.5033557 ],\n",
              "       [0.978907  ],\n",
              "       [0.978907  ],\n",
              "       [0.93959732],\n",
              "       [0.57718121],\n",
              "       [0.12655801],\n",
              "       [0.5033557 ],\n",
              "       [0.978907  ],\n",
              "       [0.978907  ],\n",
              "       [0.978907  ],\n",
              "       [0.48897411],\n",
              "       [0.64525407],\n",
              "       [0.93959732],\n",
              "       [0.978907  ],\n",
              "       [0.95589645],\n",
              "       [0.978907  ],\n",
              "       [0.978907  ],\n",
              "       [0.1620326 ],\n",
              "       [0.978907  ],\n",
              "       [0.978907  ],\n",
              "       [0.93959732],\n",
              "       [0.48897411],\n",
              "       [0.12655801],\n",
              "       [0.1620326 ],\n",
              "       [0.978907  ],\n",
              "       [0.978907  ],\n",
              "       [0.978907  ],\n",
              "       [0.48897411],\n",
              "       [0.58485139],\n",
              "       [0.93959732],\n",
              "       [0.978907  ],\n",
              "       [0.95589645],\n",
              "       [0.978907  ],\n",
              "       [0.978907  ],\n",
              "       [0.1620326 ],\n",
              "       [0.978907  ],\n",
              "       [0.978907  ],\n",
              "       [0.93959732],\n",
              "       [0.48897411],\n",
              "       [0.12655801],\n",
              "       [0.1620326 ],\n",
              "       [0.978907  ],\n",
              "       [0.978907  ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U6MBxQhzixYw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = get_model(normal_network_input,notes_len)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t2GfWVisTwuI",
        "colab_type": "code",
        "outputId": "9db31d1f-a2da-43d9-bcf3-b962976872e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "filepath = \"weights-{epoch:02d}-{loss:.2f}.hdf5\"\n",
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath,\n",
        "    monitor='loss',  # 监控的对象是loss\n",
        "    verbose=0,\n",
        "    save_best_only=True,\n",
        "    mode='min'  # 如果监控对象是val_acc则取max，是loss则取min\n",
        ")\n",
        "callbacks_list = [checkpoint]\n",
        "model.fit(normal_network_input, network_output, epochs=100, batch_size=128, callbacks=callbacks_list) #整体迭代100次，每小批128个"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "442/442 [==============================] - 59s 133ms/step - loss: 6.9474\n",
            "Epoch 2/100\n",
            "442/442 [==============================] - 62s 141ms/step - loss: 6.9446\n",
            "Epoch 3/100\n",
            "442/442 [==============================] - 62s 140ms/step - loss: 6.9417\n",
            "Epoch 4/100\n",
            "442/442 [==============================] - 62s 140ms/step - loss: 6.9384\n",
            "Epoch 5/100\n",
            "442/442 [==============================] - 62s 140ms/step - loss: 6.9347\n",
            "Epoch 6/100\n",
            "442/442 [==============================] - 62s 140ms/step - loss: 6.9302\n",
            "Epoch 7/100\n",
            "442/442 [==============================] - 62s 140ms/step - loss: 6.9244\n",
            "Epoch 8/100\n",
            "442/442 [==============================] - 62s 140ms/step - loss: 6.9168\n",
            "Epoch 9/100\n",
            "442/442 [==============================] - 62s 140ms/step - loss: 6.9056\n",
            "Epoch 10/100\n",
            "442/442 [==============================] - 62s 140ms/step - loss: 6.8877\n",
            "Epoch 11/100\n",
            "442/442 [==============================] - 62s 140ms/step - loss: 6.8534\n",
            "Epoch 12/100\n",
            "442/442 [==============================] - 62s 140ms/step - loss: 6.7770\n",
            "Epoch 13/100\n",
            "442/442 [==============================] - 62s 140ms/step - loss: 6.6447\n",
            "Epoch 14/100\n",
            "442/442 [==============================] - 62s 140ms/step - loss: 6.5138\n",
            "Epoch 15/100\n",
            "442/442 [==============================] - 62s 140ms/step - loss: 6.4132\n",
            "Epoch 16/100\n",
            "442/442 [==============================] - 62s 140ms/step - loss: 6.3289\n",
            "Epoch 17/100\n",
            "442/442 [==============================] - 62s 140ms/step - loss: 6.2612\n",
            "Epoch 18/100\n",
            "442/442 [==============================] - 62s 140ms/step - loss: 6.2007\n",
            "Epoch 19/100\n",
            "442/442 [==============================] - 62s 140ms/step - loss: 6.1416\n",
            "Epoch 20/100\n",
            "442/442 [==============================] - 62s 140ms/step - loss: 6.0961\n",
            "Epoch 21/100\n",
            "442/442 [==============================] - 62s 140ms/step - loss: 6.0563\n",
            "Epoch 22/100\n",
            "442/442 [==============================] - 62s 140ms/step - loss: 6.0206\n",
            "Epoch 23/100\n",
            "442/442 [==============================] - 62s 140ms/step - loss: 5.9874\n",
            "Epoch 24/100\n",
            "442/442 [==============================] - 62s 140ms/step - loss: 5.9590\n",
            "Epoch 25/100\n",
            "442/442 [==============================] - 62s 140ms/step - loss: 5.9348\n",
            "Epoch 26/100\n",
            "442/442 [==============================] - 62s 140ms/step - loss: 5.9119\n",
            "Epoch 27/100\n",
            "442/442 [==============================] - 62s 140ms/step - loss: 5.8906\n",
            "Epoch 28/100\n",
            "442/442 [==============================] - 62s 140ms/step - loss: 5.8762\n",
            "Epoch 29/100\n",
            "442/442 [==============================] - 62s 140ms/step - loss: 5.8588\n",
            "Epoch 30/100\n",
            "442/442 [==============================] - 62s 140ms/step - loss: 5.8452\n",
            "Epoch 31/100\n",
            "442/442 [==============================] - 62s 140ms/step - loss: 5.8314\n",
            "Epoch 32/100\n",
            "442/442 [==============================] - 62s 140ms/step - loss: 5.8244\n",
            "Epoch 33/100\n",
            "442/442 [==============================] - 62s 140ms/step - loss: 5.8101\n",
            "Epoch 34/100\n",
            "442/442 [==============================] - 62s 140ms/step - loss: 5.7989\n",
            "Epoch 35/100\n",
            "442/442 [==============================] - 62s 140ms/step - loss: 5.7906\n",
            "Epoch 36/100\n",
            "442/442 [==============================] - 62s 140ms/step - loss: 5.7816\n",
            "Epoch 37/100\n",
            "442/442 [==============================] - 62s 140ms/step - loss: 5.7738\n",
            "Epoch 38/100\n",
            "442/442 [==============================] - 62s 140ms/step - loss: 5.7683\n",
            "Epoch 39/100\n",
            "442/442 [==============================] - 62s 140ms/step - loss: 5.7586\n",
            "Epoch 40/100\n",
            "442/442 [==============================] - 62s 140ms/step - loss: 5.7531\n",
            "Epoch 41/100\n",
            "442/442 [==============================] - 62s 140ms/step - loss: 5.7458\n",
            "Epoch 42/100\n",
            "442/442 [==============================] - 62s 140ms/step - loss: 5.7398\n",
            "Epoch 43/100\n",
            "442/442 [==============================] - 62s 140ms/step - loss: 5.7339\n",
            "Epoch 44/100\n",
            "442/442 [==============================] - 62s 140ms/step - loss: 5.7319\n",
            "Epoch 45/100\n",
            "442/442 [==============================] - 62s 140ms/step - loss: 5.7272\n",
            "Epoch 46/100\n",
            "442/442 [==============================] - 62s 140ms/step - loss: 5.7208\n",
            "Epoch 47/100\n",
            "442/442 [==============================] - 62s 140ms/step - loss: 5.7172\n",
            "Epoch 48/100\n",
            "442/442 [==============================] - 62s 140ms/step - loss: 5.7126\n",
            "Epoch 49/100\n",
            "442/442 [==============================] - 62s 140ms/step - loss: 5.7092\n",
            "Epoch 50/100\n",
            "442/442 [==============================] - 62s 140ms/step - loss: 5.7056\n",
            "Epoch 51/100\n",
            "442/442 [==============================] - 62s 140ms/step - loss: 5.7001\n",
            "Epoch 52/100\n",
            "442/442 [==============================] - 62s 140ms/step - loss: 5.6929\n",
            "Epoch 53/100\n",
            "442/442 [==============================] - 62s 140ms/step - loss: 5.6962\n",
            "Epoch 54/100\n",
            "442/442 [==============================] - 62s 140ms/step - loss: 5.6925\n",
            "Epoch 55/100\n",
            "442/442 [==============================] - 62s 140ms/step - loss: 5.6897\n",
            "Epoch 56/100\n",
            "442/442 [==============================] - 62s 140ms/step - loss: 5.6884\n",
            "Epoch 57/100\n",
            "442/442 [==============================] - 62s 140ms/step - loss: 5.6833\n",
            "Epoch 58/100\n",
            "442/442 [==============================] - 62s 140ms/step - loss: 5.6791\n",
            "Epoch 59/100\n",
            "442/442 [==============================] - 62s 140ms/step - loss: 5.6784\n",
            "Epoch 60/100\n",
            "442/442 [==============================] - 62s 140ms/step - loss: 5.6778\n",
            "Epoch 61/100\n",
            "442/442 [==============================] - 62s 140ms/step - loss: 5.6743\n",
            "Epoch 62/100\n",
            "442/442 [==============================] - 62s 140ms/step - loss: 5.6721\n",
            "Epoch 63/100\n",
            "442/442 [==============================] - 62s 140ms/step - loss: 5.6735\n",
            "Epoch 64/100\n",
            "442/442 [==============================] - 62s 140ms/step - loss: 5.6711\n",
            "Epoch 65/100\n",
            "442/442 [==============================] - 62s 140ms/step - loss: 5.6643\n",
            "Epoch 66/100\n",
            "442/442 [==============================] - 62s 140ms/step - loss: 5.6675\n",
            "Epoch 67/100\n",
            "442/442 [==============================] - 62s 139ms/step - loss: 5.6649\n",
            "Epoch 68/100\n",
            "442/442 [==============================] - 62s 140ms/step - loss: 5.6628\n",
            "Epoch 69/100\n",
            "442/442 [==============================] - 62s 140ms/step - loss: 5.6612\n",
            "Epoch 70/100\n",
            "442/442 [==============================] - 62s 140ms/step - loss: 5.6595\n",
            "Epoch 71/100\n",
            "442/442 [==============================] - 62s 140ms/step - loss: 5.6602\n",
            "Epoch 72/100\n",
            "442/442 [==============================] - 62s 140ms/step - loss: 5.6584\n",
            "Epoch 73/100\n",
            "442/442 [==============================] - 62s 140ms/step - loss: 5.6519\n",
            "Epoch 74/100\n",
            "442/442 [==============================] - 62s 139ms/step - loss: 5.6522\n",
            "Epoch 75/100\n",
            "442/442 [==============================] - 62s 139ms/step - loss: 5.6540\n",
            "Epoch 76/100\n",
            "442/442 [==============================] - 62s 139ms/step - loss: 5.6473\n",
            "Epoch 77/100\n",
            "442/442 [==============================] - 62s 140ms/step - loss: 5.6458\n",
            "Epoch 78/100\n",
            "442/442 [==============================] - 62s 140ms/step - loss: 5.6490\n",
            "Epoch 79/100\n",
            "442/442 [==============================] - 62s 139ms/step - loss: 5.6486\n",
            "Epoch 80/100\n",
            "442/442 [==============================] - 62s 140ms/step - loss: 5.6439\n",
            "Epoch 81/100\n",
            "442/442 [==============================] - 62s 140ms/step - loss: 5.6431\n",
            "Epoch 82/100\n",
            "442/442 [==============================] - 62s 140ms/step - loss: 5.6432\n",
            "Epoch 83/100\n",
            "442/442 [==============================] - 62s 140ms/step - loss: 5.6416\n",
            "Epoch 84/100\n",
            "442/442 [==============================] - 62s 140ms/step - loss: 5.6389\n",
            "Epoch 85/100\n",
            "442/442 [==============================] - 62s 139ms/step - loss: 5.6421\n",
            "Epoch 86/100\n",
            "442/442 [==============================] - 62s 140ms/step - loss: 5.6387\n",
            "Epoch 87/100\n",
            "442/442 [==============================] - 62s 139ms/step - loss: 5.6391\n",
            "Epoch 88/100\n",
            "442/442 [==============================] - 62s 140ms/step - loss: 5.6368\n",
            "Epoch 89/100\n",
            "442/442 [==============================] - 62s 140ms/step - loss: 5.6343\n",
            "Epoch 90/100\n",
            "442/442 [==============================] - 62s 140ms/step - loss: 5.6340\n",
            "Epoch 91/100\n",
            "442/442 [==============================] - 62s 140ms/step - loss: 5.6314\n",
            "Epoch 92/100\n",
            "442/442 [==============================] - 62s 140ms/step - loss: 5.6322\n",
            "Epoch 93/100\n",
            "442/442 [==============================] - 62s 140ms/step - loss: 5.6267\n",
            "Epoch 94/100\n",
            "442/442 [==============================] - 62s 140ms/step - loss: 5.6313\n",
            "Epoch 95/100\n",
            "442/442 [==============================] - 62s 140ms/step - loss: 5.6262\n",
            "Epoch 96/100\n",
            "442/442 [==============================] - 62s 139ms/step - loss: 5.6284\n",
            "Epoch 97/100\n",
            "442/442 [==============================] - 62s 140ms/step - loss: 5.6253\n",
            "Epoch 98/100\n",
            "442/442 [==============================] - 62s 140ms/step - loss: 5.6277\n",
            "Epoch 99/100\n",
            "442/442 [==============================] - 62s 140ms/step - loss: 5.6270\n",
            "Epoch 100/100\n",
            "442/442 [==============================] - 62s 139ms/step - loss: 5.6256\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f7381533588>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PFwSUbadA4CK",
        "colab_type": "code",
        "outputId": "8ca7920b-82b0-44f4-ca1b-975478650568",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        }
      },
      "source": [
        "model.predict(normal_network_input)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.01083246, 0.00336389, 0.00095293, ..., 0.00486094, 0.00395192,\n",
              "        0.00083549],\n",
              "       [0.01082871, 0.00336434, 0.00095315, ..., 0.00486103, 0.00395107,\n",
              "        0.00083582],\n",
              "       [0.01082592, 0.00336442, 0.00095331, ..., 0.00486103, 0.00395048,\n",
              "        0.00083603],\n",
              "       ...,\n",
              "       [0.01086014, 0.00335825, 0.00095063, ..., 0.00486154, 0.00395987,\n",
              "        0.00083233],\n",
              "       [0.01086102, 0.00335798, 0.00095053, ..., 0.00486158, 0.00396016,\n",
              "        0.00083221],\n",
              "       [0.01086243, 0.00335755, 0.0009504 , ..., 0.00486158, 0.0039606 ,\n",
              "        0.00083203]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_IJuqMvjio0",
        "colab_type": "code",
        "outputId": "9185c0a7-b2b2-43ef-b1a2-f2b51e04bcc6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "model.evaluate(a,b)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 1ms/step - loss: 3.4243\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3.424316883087158"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CeM2eijnYhub",
        "colab_type": "code",
        "outputId": "51c0c72e-0373-4ee3-ff0a-7079a8264c72",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "randindex = np.random.randint(0, len(network_input) - 1)\n",
        "notedic = dict((i,j) for i, j in enumerate(note_name))    # 把刚才的整数还原成音调\n",
        "pattern = list(network_input[randindex])\n",
        "predictions = []\n",
        "#随机生成1000个音符\n",
        "for note_index in range(500):\n",
        "    #pattern = list(network_input[np.random.randint(0,500)])\n",
        "    prediction_input = np.reshape(pattern, (1, len(pattern), 1))\n",
        "    \n",
        "    prediction_input = prediction_input / float(notes_len)#归一化\n",
        "    prediction = model.predict(prediction_input)\n",
        "\n",
        "    if note_index <5:\n",
        "      print(prediction)\n",
        "    index = np.argmax(prediction)\n",
        "    if note_index <5:\n",
        "      print(index)\n",
        "    result = notedic[index]\n",
        "    predictions.append(result)\n",
        "    # 往后移动\n",
        "    pattern.append(np.array([index]))\n",
        "    pattern = pattern[1:len(pattern)]"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.01067295 0.00337662 0.00096615 ... 0.00484987 0.00391396 0.00085095]]\n",
            "1021\n",
            "[[0.01067835 0.00337568 0.00096571 ... 0.00484999 0.00391549 0.00085037]]\n",
            "1021\n",
            "[[0.01068478 0.00337451 0.00096519 ... 0.00485017 0.00391727 0.00084968]]\n",
            "1021\n",
            "[[0.01069233 0.00337316 0.00096458 ... 0.00485036 0.00391932 0.00084887]]\n",
            "1021\n",
            "[[0.010701   0.00337167 0.00096389 ... 0.0048506  0.00392164 0.00084795]]\n",
            "1021\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ekGYnHQ_F8cG",
        "colab_type": "code",
        "outputId": "d7778243-6d10-4855-ad6e-a12c0690fbd2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2',\n",
              " 'F#2']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXxSckoxa0RT",
        "colab_type": "code",
        "outputId": "247cf0fb-4d7a-4302-9d0c-9734f3dde372",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from music21 import stream as st\n",
        "offset = 0\n",
        "output_notes = []\n",
        "# 生成 Note（音符）或 Chord（和弦）对象\n",
        "for data in predictions:\n",
        "    if ('.' in data) or data.isdigit():\n",
        "        notes_in_chord = data.split('.')\n",
        "        notes = []\n",
        "        for current_note in notes_in_chord:\n",
        "            new_note = note.Note(int(current_note))\n",
        "            new_note.storedInstrument = instrument.Piano()\n",
        "            notes.append(new_note)\n",
        "        new_chord = chord.Chord(notes)\n",
        "        new_chord.offset = offset\n",
        "        output_notes.append(new_chord)\n",
        "    else:\n",
        "        new_note = note.Note(data)\n",
        "        new_note.offset = offset\n",
        "        new_note.storedInstrument = instrument.Piano()\n",
        "        output_notes.append(new_note)\n",
        "    offset += 1\n",
        "# 创建音乐流（Stream）\n",
        "midi_stream = st.Stream(output_notes)\n",
        "# 写入 MIDI 文件\n",
        "midi_stream.write('midi', fp='output1.mid')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'output1.mid'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZz3Z9N3C8A8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2GgGFUK9a6-a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}